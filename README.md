# Virtual-GPTeacher-Language-AI-Tutor (The English version is below this one)
GPTeacher ‚Äî —ç—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ—Ç–æ—Ç–∏–ø –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ AI-–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤.
–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—è —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ—Å–æ–º —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –¥–∏–Ω–∞–º–∏–∫, –∞ –¥–∏–∞–ª–æ–≥ –≤–µ–¥—ë—Ç —Å –æ–±–ª–∞—á–Ω—ã–º LLM.


**GPTeacher ‚Äî –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤** 


‚ö† –ü—Ä–æ–µ–∫—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –≤ 2023‚Äì2024 –≥–≥. –∏ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–∞–Ω–Ω–∏–π —ç—Ç–∞–ø —Ä–∞–∑–≤–∏—Ç–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö LLM-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤.
–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ API-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –º–æ–≥–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –∏–ª–∏ —Å—Ç–∞—Ç—å –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏. –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ —á–∞—Å—Ç—å –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π R&D —Ä–∞–±–æ—Ç—ã –∏ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–µ –∫–∞–∫ production-–≥–æ—Ç–æ–≤—ã–π –ø—Ä–æ–¥—É–∫—Ç.

‚∏ª

üåü **–ß—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–µ**


*GPTeacher ‚Äî —ç—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ—Ç–∏–ø –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ AI-—Ç—å—é—Ç–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π:*

 ‚Ä¢ –≤–µ–¥—ë—Ç –∂–∏–≤–æ–π –≥–æ–ª–æ—Å–æ–≤–æ–π —É—Ä–æ–∫ –±–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π
 
 ‚Ä¢ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—á–∏—Ç—å —è–∑—ã–∫ —á–µ—Ä–µ–∑ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∏–∞–ª–æ–≥–∏ –∏ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–∫—Å—Ç—É
 
 ‚Ä¢ —Å–æ—á–µ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ + –æ–±–ª–∞—á–Ω—ã–π LLM + —Å–∏–Ω—Ç–µ–∑ –≥–æ–ª–æ—Å–∞
 


‚∏ª

üî• **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–ª–∏—á–∞–ª–∏ –ø—Ä–æ–µ–∫—Ç –Ω–∞ –º–æ–º–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏**

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å**          /          **–°—Ç–∞—Ç—É—Å**

–†–∞–∑–≥–æ–≤–æ—Ä–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –≥–æ–ª–æ—Å–æ–º       ‚úÖ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞, –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π

12+ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤             ‚úÖ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ä–æ–ª–µ–π

–ö–∞—Å—Ç–æ–º–Ω—ã–µ TTS-–≥–æ–ª–æ—Å–∞               ‚úÖ 10+ –º—É–∂—Å–∫–∏—Ö/–∂–µ–Ω—Å–∫–∏—Ö

–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞                   ‚úÖ —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Ä–æ–∫–æ–≤

–õ–æ–∫–∞–ª—å–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å             ‚ö† —á–∞—Å—Ç–∏—á–Ω–∞—è, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –Ω–æ—É—Ç–±—É–∫–µ

–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞              ‚ö† –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è, synthetic –∑–≤—É—á–∞–Ω–∏–µ

–ü–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞              –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç



‚∏ª

üß† **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**


<img width="1206" height="436" alt="image" src="https://github.com/user-attachments/assets/5b46a163-340b-47b4-a9f1-532bd079bd85" />




–ü–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏:

 1. **Audio Input (microphone stream)**

 ‚Ä¢ –ó–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ sounddevice.RawInputStream

 ‚Ä¢ 16-–±–∏—Ç–Ω—ã–π –ø–æ—Ç–æ–∫ int16, 1 –∫–∞–Ω–∞–ª, 8000 blocksize –±—É—Ñ–µ—Ä
 
 2. **Speech-to-Text (–ª–æ–∫–∞–ª—å–Ω–æ)**

 ‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º/–∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–æ–º–æ—â—å—é Vosk
 
 ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã–µ –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ (–ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)
 
 3. **LLM-–ª–æ–≥–∏–∫–∞ (–æ–±–ª–∞–∫–æ)**
    
 ‚Ä¢ –û—Ç–≤–µ—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –º–æ–¥–µ–ª—å—é GigaChat
 
 ‚Ä¢ payload —Ö—Ä–∞–Ω–∏—Ç –¥–∏–∞–ª–æ–≥ –∫–∞–∫ messages.append(role=USER/ASSISTANT)
 
 4. **Text-to-Speech**
    
 ‚Ä¢ –û—Ç–≤–µ—Ç LLM –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –≤ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Yandex SpeechKit
 
 ‚Ä¢ –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ lpcm ‚Üí –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ PyAudio stream
 
 5. **–°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞**
    
 ‚Ä¢ –ê–∫—Ç–∏–≤–∞—Ü–∏—è —É—Ä–æ–∫–∞ ‚Äî –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º (start_chat_msgs)
 
 ‚Ä¢ –ï—Å–ª–∏ partial result –¥–ª–∏—Ç—Å—è 30+ —Å–µ–∫ –±–µ–∑ –∫–æ–º–∞–Ω–¥—ã –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, —á–∞—Ç —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è
 
 ‚Ä¢ –ï—Å–ª–∏ –≤ —á–∞—Ç–µ, –Ω–æ 30 —Å–µ–∫ –Ω–µ—Ç —Ä–µ—á–∏ ‚Üí –æ–±—ä—è–≤–ª—è–µ—Ç—Å—è –ù–æ–≤—ã–π —á–∞—Ç/New chat

‚∏ª

‚öôÔ∏è **–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è**

1.üé§ **–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π —Å—Ç–∞—Ä—Ç —É—Ä–æ–∫–æ–≤**

–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–µ—Å—Å–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–∏–∑–Ω—ë—Å –æ–¥–Ω—É –∏–∑ —Ñ—Ä–∞–∑:

start_chat_msgs = ["–¥–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º", "let's talk", "hablamos?", "parliamo?"]

–≠—Ç–æ —ç–º—É–ª—è—Ü–∏—è wake-up intent –±–µ–∑ NLU-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.

2. üß© **–ú—É–ª—å—Ç–∏—è–∑—ã–∫–æ–≤–æ–π intent-triggering —á–µ—Ä–µ–∑ any(start in data)**

–§—Ä–∞–∑—ã —Å—Ç–∞—Ä—Ç–∞ –¥–µ—Ç–µ–∫—Ç—è—Ç—Å—è –Ω–∞–∏–≤–Ω—ã–º sub-string matching, —á—Ç–æ:

 ‚Ä¢ —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ
 
 ‚Ä¢ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
 
 ‚Ä¢ –Ω–æ –¥–∞—ë—Ç False Positives (–ø–æ—ç—Ç–æ–º—É –∞–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞)

3. üß† **Long-Memory payload**

–î–∏–∞–ª–æ–≥ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:

payload.messages.append(Messages(role=USER, content=data))

payload.messages.append(message_from_assistant)

–≠—Ç–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π in-context memory –¥–ª—è LLM –±–µ–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

4. ‚è≥ **–¢–∞–π–º–µ—Ä —Å–±—Ä–æ—Å–∞ —á–∞—Ç–æ–≤**

if end - start > 30:

    chat = False

–ù—É–∂–Ω–æ –¥–ª—è:

 ‚Ä¢ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª–∏–Ω—ã –∞—É–¥–∏–æ-–±—É—Ñ–µ—Ä–∞
 
 ‚Ä¢ –≤—ã–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–∫–æ–≤ –ø–æ 30 —Å–µ–∫-–∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º (–¥–ª—è debug –∏ –∞–Ω–∞–ª–∏–∑–∞)


‚öôÔ∏è **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Ä–æ–∫–æ–≤ (config.json)**

–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –º–æ–∂–Ω–æ –≥–∏–±–∫–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é JSON-—Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–∫—Ä–∏–ø—Ç–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, —è–∑—ã–∫ —É—Ä–æ–∫–∞, —Ç–∏–ø —É—Ä–æ–∫–∞, –≥–æ–ª–æ—Å –∏ —Ñ–æ—Ä–º–∞—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è.

üìå *–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∫–æ–Ω—Ñ–∏–≥–∞*

<img width="1629" height="292" alt="image" src="https://github.com/user-attachments/assets/0c256028-ea63-4876-80aa-97f643f7128d" />



config.json —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, —Ñ–æ—Ä–º–∞—Ç–æ–º —É—Ä–æ–∫–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π —Å–µ—Å—Å–∏–∏. –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç, –∫–∞–∫ –±–æ—Ç –±—É–¥–µ—Ç –≤–µ—Å—Ç–∏ —É—Ä–æ–∫.

**–ü–æ–ª–µ** / **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**

‚Ä¢ bot_type ‚Äî —Ç–∏–ø —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—É—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
(–≤ legacy-–≤–µ—Ä—Å–∏–∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å –Ω–∞ ChatGPT 4.0 –∏ GigaChat-Pro, —Å–µ–π—á–∞—Å –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ –¥—Ä—É–≥–æ–π LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä)

 ‚Ä¢ role_or_task ‚Äî –∑–∞–¥–∞—ë—Ç —Ä–æ–ª—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ —É—Ä–æ–∫–µ
(–Ω–∞–ø—Ä–∏–º–µ—Ä: English teacher. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è 12+ —è–∑—ã–∫–æ–≤—ã—Ö —Ä–æ–ª–µ–π ‚Äî –∑–∞–¥–∞—ë—Ç—Å—è –ø—Ä–æ–º–ø—Ç–æ–º)

 ‚Ä¢ lesson_type ‚Äî —Ñ–æ—Ä–º–∞—Ç –ø—Ä–∞–∫—Ç–∏–∫–∏
 
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã:

 ‚Ä¢ dialogue_on_topic ‚Äî –∂–∏–≤–æ–π –¥–∏–∞–ª–æ–≥ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–µ–º–µ
 
 ‚Ä¢ questions_on_text ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —É—á–µ–±–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É
 
 ‚Ä¢ topic_of_dialogue ‚Äî —Ç–µ–º–∞ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è —É—Ä–æ–∫–∞ –≤ —Ä–µ–∂–∏–º–µ dialogue_on_topic
(–∑–∞–¥–∞—ë—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º —É—Ä–æ–∫–∞)

 ‚Ä¢ text_for_questions ‚Äî —Ç–µ–∫—Å—Ç, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –±–æ—Ç –±—É–¥–µ—Ç —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã
(–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ questions_on_text)

 ‚Ä¢ save_lesson_to_file ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Ä–æ–∫–∞ –≤ —Ñ–∞–π–ª (true / false)
(–µ—Å–ª–∏ true ‚Äî –ø–æ—Å–ª–µ —É—Ä–æ–∫–∞ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ä–µ—á–∏ —É—á–µ–Ω–∏–∫–∞

‚∏ª


üóÇ **–ö–∞–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω—É–∂–Ω—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞**

requirements.txt

torch>=2.1.0

numpy>=1.22.0

pandas>=2.0.0

transformers>=4.36.0

accelerate>=0.25.0

bitsandbytes>=0.41.0

vosk>=0.3.45

sounddevice>=0.4.6

pyaudio>=0.2.13

requests>=2.31.0


‚∏ª

üíæ **–ö–∞–∫ –∑–∞–ø—É—Å–∫–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ**

1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
   
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
  
3. –°–æ–∑–¥–∞—Ç—å API-–∫–ª—é—á–∏
  
4. –ó–∞–ø—É—Å—Ç–∏—Ç—å python —Ñ–∞–π–ª
   
5. –°–∫–∞–∑–∞—Ç—å —Ñ—Ä–∞–∑—É –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω
   
6. –ù–∞—á–∞—Ç—å —É—Ä–æ–∫ –≥–æ–ª–æ—Å–æ–º
   
7. –î–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Ctrl+C


‚∏ª

üîÆ **–ö–∞–∫ –º–æ–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–µ–∫—Ç**

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ–±–Ω–æ–≤–∏—Ç—å —ç—Ç–æ—Ç —Å—Ç–∞—Ä—ã–π –ø—Ä–æ—Ç–æ—Ç–∏–ø ‚Üí –≤–æ—Ç –∫—É–¥–∞ —Å–º–æ—Ç—Ä–µ—Ç—å:

 ‚Ä¢ –ó–∞–º–µ–Ω–∞ string matching –Ω–∞ üß© NLU intent classifier (BERT/ChatGPT intent)
 
 ‚Ä¢ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –±–∞–∑—ã –ø–∞–º—è—Ç–∏ (SQLite / VectorDB)
 
 ‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ timm (–∫–∞–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–æ—Å—å –¥–ª—è Wildlife –∑–∞–¥–∞—á)
 
 ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ TTS models

‚∏ª

üß™ **–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞**

–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —É—Å—Ç–∞—Ä–µ–≤–∞–Ω–∏–µ, —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø–æ–∫–∞–∑–∞–ª –≤–∞–∂–Ω–æ–µ:

‚ú® –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å ‚Äú–≥–æ–≤–æ—Ä–∏—Ç—å‚Äù —Å LLM –±–µ–∑ –ø–µ—á–∞—Ç–∏

‚ú® –¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —É—Ä–æ–∫–æ–≤ –≤ JSON –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –ø–∞–º—è—Ç—å

‚ú® —Å–æ–∑–¥–∞—Ç—å –ø–µ—Ä–≤—ã–π open-source voice-—Ç—å—é—Ç–æ—Ä–∞ –Ω–∞ –±–∞–∑–µ GPT —Å—Ä–µ–¥–∏ —à–∫–æ–ª—å–Ω—ã—Ö –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤

*–ü—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª—Å—è –Ω–∞ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –∏ AI-—Ñ–æ—Ä—É–º–∞—Ö, –∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≤–µ–ª–∞—Å—å –ø—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –ª–∏–Ω–≥–≤–∏—Å—Ç–æ–≤.
–≠—Ç–æ –±—ã–ª —Å—Ç–∞—Ä—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–µ–≥–æ–¥–Ω—è –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–∏—Ç—å –Ω–∞ –Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö üîÑ.*

‚∏ª

üè∑ **–ê–≤—Ç–æ—Ä—Å—Ç–≤–æ**

–î–º–∏—Ç—Ä–∏–µ–≤–∞ –ï–≤–≥–µ–Ω–∏—è –î–º–∏—Ç—Ä–∏–µ–≤–Ω–∞, –ú–æ—Å–∫–≤–∞, 2023 -2024 –≥–≥.

https://t.me/angel_eugeniya

eugeniya.dm@gmail.com

> –≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Ä–∞–∑–º–µ—â–µ–Ω –≤ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–∞ GitHub –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤–∫–ª–∞–¥–æ–≤. –û–Ω –Ω–µ –æ—Ç—Ä–∞–∂–∞–µ—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—é.


**ENGLISH**

**Virtual-GPTeacher-Language-AI-Tutor** 

*GPTeacher ‚Äî Voice-First LLM Language Tutor (Legacy Prototype)*

‚ö†Ô∏è Originally prototyped and demonstrated in 2023‚Äì2024.
This repository is preserved as part of a research, hardware-integrated AI prototype portfolio, not as a production-ready system. Some APIs, model endpoints, and voices may have changed since the original development phase.

‚∏ª

üåü **What is GPTeacher?**

GPTeacher is an experimental voice-only AI language tutor that:

 ‚Ä¢ interacts without a keyboard, using microphone capture and speaker output
 
 ‚Ä¢ enables unlimited spoken conversation practice
 
 ‚Ä¢ supports 12+ languages via configurable system roles
 
 ‚Ä¢ combines:
 
 1. Local offline speech recognition
 
 2. Cloud-hosted LLM responses
 
 3. Text-to-speech voice synthesis
 
 4. Session segmentation via silence timers
 
 ‚Ä¢ uses a 3D-printed robotic head based on open-source designs as its audio output hardware

‚∏ª

üî• **Key Capabilities at the Time of Development**

**Feature** / **Status**

Voice conversation practice ‚úÖ implemented, no limits

12+ foreign languages ‚úÖ via role configuration

Custom TTS voices ‚úÖ 10+ male/female

Lesson history for progress analysis ‚úÖ supported

Local autonomy ‚ö† partial, ran on laptop

Voice realism ‚ö† synthetic sounding

Pedagogical evaluation experience builts-in


‚∏ª

üß† **Technical Architecture**


<img width="1206" height="436" alt="image" src="https://github.com/user-attachments/assets/9287f923-2a4f-4b15-ae5d-0f571e9fb578" />


*Processing pipeline*

 1.  **Audio Input (Microphone Stream Capture)**
 
 ‚Ä¢ Audio is captured using sounddevice.RawInputStream
 
 ‚Ä¢ Format: 16-bit int16, 1 channel, 8000 frame buffer
 
 2.  **Speech-to-Text (Offline, Local)**
 
 ‚Ä¢ Speech is recognized using local acoustic models from Vosk Community
 
 ‚Ä¢ No internet connection is needed for recognition
 
 ‚Ä¢ English and Russian language models are supported
 
 3.  **LLM Response Generation (Cloud)**
 
 ‚Ä¢ Responses were generated using an early version of GigaChat
 
 ‚Ä¢ Dialogue was stored in a payload.messages.append(role=USER/ASSISTANT) chain

 4.  **Text-to-Speech (TTS Voice Synthesis)**

 ‚Ä¢ LLM reply text is converted to audio using Yandex SpeechKit
 
 ‚Ä¢ Output format: lpcm played via PyAudio stream
 
 5.  **Session Control & Auto-Reset**
 
 ‚Ä¢ The assistant ‚Äúwakes up‚Äù using na√Øve substring intent detection (any(start in data))
 
 ‚Ä¢ If partial speech input exceeds 30 sec without activation intent, chat resets
 
 ‚Ä¢ If silence lasts 30 sec during session, assistant announces:
‚ÄúNew chat started‚Äù / ‚Äú–ù–æ–≤—ã–π —á–∞—Ç‚Äù

‚∏ª

‚öôÔ∏è **Core Technical Design Choices**

1. üé§**Wake-Up Intent Imitation (No NLU Model)**

start_chat_msgs = ["–¥–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º", "let's talk", "hablamos?", "parliamo?"]

A fast, model-free wake-word intent simulation.

2. üß© **Multilingual Triggering via Sub-String Matching**

if any(msg in data for msg in start_chat_msgs)

‚úÖ Fast, no extra ML model required

‚ö† Not reliable for production (false positives)

3. üß† **In-Context Dialogue Memory**

payload.messages.append(Messages(role=USER, content=data))

payload.messages.append(message_from_assistant)

A lightweight chat memory stored directly in the prompt.

4. ‚è≥ **Chat Reset Timer**

if end - start > 30:

    chat = False

Ensures conversation is segmented into short lesson sessions.

‚∏ª


‚öôÔ∏è **Lesson configuration (config.json)**

The assistant can be flexibly configured via a JSON configuration file.

All parameters are loaded at startup and define:
 
 ‚Ä¢ which LLM is used
 
 ‚Ä¢ what teacher role the assistant plays
 
 ‚Ä¢ which lesson format is active
 
 ‚Ä¢ which language and voice are used
 
 ‚Ä¢ how long to wait before auto-resetting the chat

üìå **Main config fields**

<img width="1629" height="292" alt="image" src="https://github.com/user-attachments/assets/b885d532-849f-4030-b7c1-a1ccf5423b0c" />


 ‚Ä¢ bot_type ‚Äî specifies the language model or LLM provider used by the assistant
(legacy version focused on ChatGPT 4.0 or GigaChat-Pro, can now be replaced with other cloud-based LLMs)

 ‚Ä¢ role_or_task ‚Äî defines the assistant‚Äôs role during the lesson
(e.g., English teacher. The system supports 12+ language teaching roles provided via prompt instructions)

 ‚Ä¢ lesson_type ‚Äî determines the format of the language practice
 
Currently supported modes:

 ‚Ä¢ dialogue_on_topic ‚Äî natural conversation based on a given topic
 
 ‚Ä¢ questions_on_text ‚Äî sequential questions generated from a learning text
 
 ‚Ä¢ topic_of_dialogue ‚Äî the topic used when the lesson is in dialogue_on_topic mode
(provided by the user before or during session activation)

 ‚Ä¢ text_for_questions ‚Äî the study text used to generate questions in questions_on_text mode
(ignored if the lesson is not text-based)

 ‚Ä¢ save_lesson_to_file ‚Äî enables or disables lesson logging to a file
(if true ‚Üí a lesson log is created for later error analysis and progress review)

‚∏ª


üóÇ **Required Dependencies**

requirements.txt

torch>=2.0.0

numpy>=1.22.0

pandas>=2.0.0

transformers>=4.36.0

accelerate>=0.25.0

bitsandbytes>=0.41.0

vosk>=0.3.45

sounddevice>=0.4.6

pyaudio>=0.2.13

requests>=2.31.0


‚∏ª

üöÄ **Installing and Running Locally**

1. Clone the repository from GitHub

2. Install dependencies

3. Create your API keys

4. Run the Python script

5. Activate with your voice using one of the intent phrases

6. Start your lesson by speaking

7. Stop the program using Ctrl+C


‚∏ª

üîÆ **Modern Update Path for the Prototype**

If you want to revive and modernize this legacy prototype, consider:

 ‚Ä¢ replacing string matching with an intent classifier (BERT or OpenAI intent models)
 
 ‚Ä¢ storing persistent memory in SQLite or a vector database
 
 ‚Ä¢ improving voice realism with modern TTS models
 
 ‚Ä¢ moving logic from laptop to a Raspberry Pi device for full autonomy

‚∏ª

üß™ **Historical Value**

Even though the prototype may now be outdated, it demonstrated:

‚ú® that you can speak with an LLM without typing

‚ú® that JSON configs can act as early ‚Äúlesson memory‚Äù

‚ú® one of the first open voice-based LLM tutoring prototypes built at school level


Development was assisted by university linguists at an early stage, and the project was presented at engineering and AI forums.

‚∏ª

üè∑Ô∏è **Author**

Evgeniya Dmitrieva 
üìç Moscow, Russia, 2023-2024

Acoustic models sourced from Vosk Community, TTS powered by Yandex SpeechKit, and LLM connected to GigaChat.

Me on Telegram: https://t.me/angel_eugeniya

eugeniya.dm@gmail.com

> This repository is hosted under a neutral GitHub organization for portfolio preservation and contribution tracking. It does not reflect employer affiliation.




